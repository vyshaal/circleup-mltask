{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing all the packages needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "\n",
    "response = pd.read_excel('Data science take home Datasets.xlsx', sheetname='user')\n",
    "features = pd.read_excel('Data science take home Datasets.xlsx', sheetname='user_features')\n",
    "ftd = pd.read_excel('Data science take home Datasets.xlsx', sheetname='model_test_file')\n",
    "\n",
    "df = pd.merge(response, features, on = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()\n",
    "# no nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftd = ftd.iloc[:,0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1',\n",
       " 'var_2',\n",
       " 'var_3',\n",
       " 'var_4',\n",
       " 'var_5',\n",
       " 'var_6',\n",
       " 'var_7',\n",
       " 'var_8',\n",
       " 'var_9',\n",
       " 'var_10',\n",
       " 'var_11']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ftd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28be5b38e10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x8syTZ4l5386gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28be6737f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#exploratory data analysis\n",
    "#plt.xlim([0, 250])\n",
    "#var_11 needs log transformation\n",
    "#var_10 needs log transformation\n",
    "# 6-11 needs log transformation\n",
    "# look for better transformation to handle 3\n",
    "\n",
    "df.var_9.plot(kind = 'kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['var_11'] = (df['var_11']+1).apply(np.log)\n",
    "df['var_10'] = (df['var_10']+1).apply(np.log)\n",
    "df['var_9'] = (df['var_9']+1).apply(np.log)\n",
    "df['var_8'] = (df['var_8']+1).apply(np.log)\n",
    "df['var_7'] = (df['var_7']+1).apply(np.log)\n",
    "df['var_6'] = (df['var_6']+1).apply(np.log)\n",
    "\n",
    "ftd['var_11'] = (ftd['var_11']+1).apply(np.log)\n",
    "ftd['var_10'] = (ftd['var_10']+1).apply(np.log)\n",
    "ftd['var_9'] = (ftd['var_9']+1).apply(np.log)\n",
    "ftd['var_8'] = (ftd['var_8']+1).apply(np.log)\n",
    "ftd['var_7'] = (ftd['var_7']+1).apply(np.log)\n",
    "ftd['var_6'] = (ftd['var_6']+1).apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>user_id</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>154531</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1740115</td>\n",
       "      <td>38.637588</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>156315</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>9803192</td>\n",
       "      <td>30.901522</td>\n",
       "      <td>11</td>\n",
       "      <td>237</td>\n",
       "      <td>1.7553</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>17</td>\n",
       "      <td>0.79306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>149607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3279</td>\n",
       "      <td>3694516</td>\n",
       "      <td>45.933998</td>\n",
       "      <td>329</td>\n",
       "      <td>638</td>\n",
       "      <td>13.1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1313</td>\n",
       "      <td>380</td>\n",
       "      <td>0.94425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26755</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>18185084</td>\n",
       "      <td>34.120554</td>\n",
       "      <td>162</td>\n",
       "      <td>65</td>\n",
       "      <td>2.4769</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>12</td>\n",
       "      <td>0.57251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>149734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>23.700552</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>5.0404</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>156</td>\n",
       "      <td>0.45718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>154440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1457</td>\n",
       "      <td>2715970</td>\n",
       "      <td>32.092002</td>\n",
       "      <td>85</td>\n",
       "      <td>948</td>\n",
       "      <td>7.6667</td>\n",
       "      <td>0</td>\n",
       "      <td>1391</td>\n",
       "      <td>69</td>\n",
       "      <td>0.93374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3394</td>\n",
       "      <td>1800677</td>\n",
       "      <td>35.434698</td>\n",
       "      <td>33</td>\n",
       "      <td>394</td>\n",
       "      <td>16.1117</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>202</td>\n",
       "      <td>0.93463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>162052</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6342</td>\n",
       "      <td>1465836</td>\n",
       "      <td>41.776283</td>\n",
       "      <td>13</td>\n",
       "      <td>343</td>\n",
       "      <td>13.6880</td>\n",
       "      <td>0</td>\n",
       "      <td>4094</td>\n",
       "      <td>89</td>\n",
       "      <td>0.93730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>153152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5714</td>\n",
       "      <td>1775211</td>\n",
       "      <td>25.836320</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>22.5323</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>664</td>\n",
       "      <td>0.91187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>151099</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8871</td>\n",
       "      <td>9405262</td>\n",
       "      <td>27.340693</td>\n",
       "      <td>17</td>\n",
       "      <td>934</td>\n",
       "      <td>6.7730</td>\n",
       "      <td>0</td>\n",
       "      <td>2442</td>\n",
       "      <td>218</td>\n",
       "      <td>0.90822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   response  user_id  var_1  var_2  var_3     var_4      var_5  var_6  var_7  \\\n",
       "0         0   154531      1      1      0   1740115  38.637588     26      0   \n",
       "1         0   156315      1      1    362   9803192  30.901522     11    237   \n",
       "2         0   149607      1      1   3279   3694516  45.933998    329    638   \n",
       "3         0    26755      1      1    213  18185084  34.120554    162     65   \n",
       "4         0   149734      0      0    226         0  23.700552      3     99   \n",
       "5         1   154440      1      1   1457   2715970  32.092002     85    948   \n",
       "6         1   151098      1      1   3394   1800677  35.434698     33    394   \n",
       "7         1   162052      1      1   6342   1465836  41.776283     13    343   \n",
       "8         0   153152      1      1   5714   1775211  25.836320      3     62   \n",
       "9         0   151099      1      1   8871   9405262  27.340693     17    934   \n",
       "\n",
       "     var_8  var_9  var_10  var_11   var_12  \n",
       "0   0.0000      0    2542       0  0.87499  \n",
       "1   1.7553      0     117      17  0.79306  \n",
       "2  13.1270      0    1313     380  0.94425  \n",
       "3   2.4769      0     168      12  0.57251  \n",
       "4   5.0404      0     119     156  0.45718  \n",
       "5   7.6667      0    1391      69  0.93374  \n",
       "6  16.1117      0     145     202  0.93463  \n",
       "7  13.6880      0    4094      89  0.93730  \n",
       "8  22.5323      0     187     664  0.91187  \n",
       "9   6.7730      0    2442     218  0.90822  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting data into train and test \n",
    "msk = np.random.rand(len(df)) < 0.6\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "X = train.iloc[:,2:]\n",
    "Y = train.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ML_model_application(input_variables, outcome_variable, test_data):\n",
    "    #logistic regression\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(input_variables, outcome_variable)\n",
    "    lr_test_predicted = lr.predict(test_data.iloc[:,2:])\n",
    "    lr_cf_mx = confusion_matrix(test_data.iloc[:,0], lr_test_predicted)\n",
    "    lr_accuracy = (lr_cf_mx[1][1]+lr_cf_mx[0][0])*100/(lr_cf_mx[1][1]+lr_cf_mx[1][0]+lr_cf_mx[0][1]+lr_cf_mx[0][0])\n",
    "    lr_recall = recall_score(test_data.iloc[:,0], lr_test_predicted)\n",
    "    \n",
    "    #random forest classifier\n",
    "    rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    rfc.fit(input_variables,outcome_variable)\n",
    "    rfc_test_predicted = rfc.predict(test_data.iloc[:,2:])\n",
    "    rfc_cf_mx = confusion_matrix(test_data.iloc[:,0], rfc_test_predicted)\n",
    "    rfc_accuracy = (rfc_cf_mx[1][1]+rfc_cf_mx[0][0])*100/(rfc_cf_mx[1][1]+rfc_cf_mx[1][0]+rfc_cf_mx[0][1]+rfc_cf_mx[0][0])\n",
    "    rfc_recall = recall_score()\n",
    "    \n",
    "    #support vector machine\n",
    "    svc = svm.SVC()\n",
    "    svc.fit(input_variables, outcome_variable)\n",
    "    svc_test_predicted = svc.predict(test_data.iloc[:,2:])\n",
    "    svc_cf_mx = confusion_matrix(test_data.iloc[:,0], svc_test_predicted)\n",
    "    svc_accuracy = (svc_cf_mx[1][1]+svc_cf_mx[0][0])*100/(svc_cf_mx[1][1]+svc_cf_mx[1][0]+svc_cf_mx[0][1]+svc_cf_mx[0][0])\n",
    "    \n",
    "    \n",
    "    #Gradient boost\n",
    "    xgb = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3, min_samples_split=2, \n",
    "                                          min_samples_leaf=1, subsample=1,max_features='sqrt', random_state=10)    \n",
    "    xgb.fit(input_variables, outcome_variable)\n",
    "    xgb_test_predicted = xgb.predict(test_data.iloc[:,2:])\n",
    "    xgb_cf_mx = confusion_matrix(test_data.iloc[:,0], xgb_test_predicted)\n",
    "    xgb_accuracy = (xgb_cf_mx[1][1]+xgb_cf_mx[0][0])*100/(xgb_cf_mx[1][1]+xgb_cf_mx[1][0]+xgb_cf_mx[0][1]+xgb_cf_mx[0][0])\n",
    "\n",
    "    \n",
    "    highest_accuracy = max([lr_accuracy, rfc_accuracy, svc_accuracy, xgb_accuracy])\n",
    "    if (highest_accuracy == lr_accuracy):\n",
    "        ML_model = 'logistic regression'\n",
    "    elif (highest_accuracy == rfc_accuracy):\n",
    "        ML_model = 'random forest classifier'\n",
    "    elif (highest_accuracy == xgb_accuracy):\n",
    "        ML_model = 'Gradient boost classifier'\n",
    "    else:\n",
    "        ML_model = 'support vector machine'\n",
    "    \n",
    "    return lr_accuracy, rfc_accuracy, svc_accuracy, xgb_accuracy,\n",
    "#ML_model + ' with accuracy ' + str(highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.529357374017565,\n",
       " 88.950531668978272,\n",
       " 85.529357374017565,\n",
       " 90.013869625520115)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_model_application(X,Y,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
